# Socially-Aware Navigation with Reinforcement Learning

This repository contains a reinforcement learning framework for socially-aware navigation in a 2D grid-based environment. The agent learns to navigate toward a goal while avoiding human obstacles, whose positions and orientations are considered in a social energy map.

## ğŸ§  Key Features

- **Custom GridWorld Environment**: Supports arbitrary agent start/end positions, human positions, and orientations.
- **Social Energy Map**: Derived from human location and facing direction.
- **Reinforcement Learning**: Uses A2C or PPO via Stable-Baselines3.
- **Visualization**: Pygame-based rendering and trajectory visualization.
- **Logging**: Automatically logs episode reward, route, and steps.
- **Trajectory Smoothing**: Optional Gaussian smoothing after training.

## ğŸ“ Project Structure

social_nav_rl/

â”œâ”€â”€ envs/

â”‚ â””â”€â”€ gridworld_env.py # Custom RL environment

â”œâ”€â”€ scripts/

â”‚ â”œâ”€â”€ train.py # Main training script

â”‚ â””â”€â”€ test.py # Model testing script

â”œâ”€â”€ utils/

â”‚ â”œâ”€â”€ callbacks.py # Episode tracking and logging

â”‚ â”œâ”€â”€ smooth.py # Gaussian smoothing utils

â”‚ â””â”€â”€ arg_parser.py # CLI argument parser

â”œâ”€â”€ energy_map/

â”‚ â””â”€â”€ normalized_get_eng_map.py

â”œâ”€â”€ log/ # Log files

â”œâ”€â”€ pic/ # Rendered trajectories

â”œâ”€â”€ main.py # Default entry point

â”œâ”€â”€ requirements.txt

â””â”€â”€ README.md


## ğŸš€ Quick Start

### 1. Install dependencies

```bash
pip install -r requirements.txt
```


### 2. Train the model

```bash
python scripts/train.py
```

You can customize the training by modifying CLI arguments, such as:
```bash
python scripts/train.py --start "[450, 150]" --end "[150, 450]" --n_people 3
```
 
### 3. Test the model (optional)
```bash
python scripts/test.py
```
## CLI Arguments

| Argument            | Description                          | Default                |
| ------------------- | ------------------------------------ | ---------------------- |
| `--start`           | Agent start position                 | `[13.5*33, 4.5*33]`    |
| `--end`             | Agent goal position                  | `[4.5*33, 13.5*33]`    |
| `--n_people`        | Number of human obstacles            | `3`                    |
| `--coordinates`     | List of human positions              | `[(4.5*33,3*33), ...]` |
| `--orientation`     | List of human orientations (degrees) | `[-90, 90, -90]`       |
| `--total_timesteps` | Number of training timesteps         | `10000`                |

